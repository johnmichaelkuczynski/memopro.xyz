// EXACT USER-SPECIFIED 4-PHASE INTELLIGENCE EVALUATION PROTOCOL

const EXACT_COMPLETE_QUESTIONS = `IS IT INSIGHTFUL? 
DOES IT DEVELOP POINTS? (OR, IF IT IS A SHORT EXCERPT, IS THERE EVIDENCE THAT IT WOULD DEVELOP POINTS IF EXTENDED)? 
IS THE ORGANIZATION MERELY SEQUENTIAL (JUST ONE POINT AFTER ANOTHER, LITTLE OR NO LOGICAL SCAFFOLDING)? OR ARE THE IDEAS ARRANGED, NOT JUST SEQUENTIALLY BUT HIERARCHICALLY? 
IF THE POINTS IT MAKES ARE NOT INSIGHTFUL, DOES IT OPERATE SKILLFULLY WITH CANONS OF LOGIC/REASONING. 
ARE THE POINTS CLICHES? OR ARE THEY "FRESH"? 
DOES IT USE TECHNICAL JARGON TO OBFUSCATE OR TO RENDER MORE PRECISE? 
IS IT ORGANIC? DO POINTS DEVELOP IN AN ORGANIC, NATURAL WAY? DO THEY 'UNFOLD'? OR ARE THEY FORCED AND ARTIFICIAL? 
DOES IT OPEN UP NEW DOMAINS? OR, ON THE CONTRARY, DOES IT SHUT OFF INQUIRY (BY CONDITIONALIZING FURTHER DISCUSSION OF THE MATTERS ON ACCEPTANCE OF ITS INTERNAL AND POSSIBLY VERY FAULTY LOGIC)? 
IS IT ACTUALLY INTELLIGENT OR JUST THE WORK OF SOMEBODY WHO, JUDGING BY THE SUBJECT-MATTER, IS PRESUMED TO BE INTELLIGENT (BUT MAY NOT BE)? 
IS IT REAL OR IS IT PHONY? 
DO THE SENTENCES EXHIBIT COMPLEX AND COHERENT INTERNAL LOGIC? 
IS THE PASSAGE GOVERNED BY A STRONG CONCEPT? OR IS THE ONLY ORGANIZATION DRIVEN PURELY BY EXPOSITORY (AS OPPOSED TO EPISTEMIC) NORMS?
IS THERE SYSTEM-LEVEL CONTROL OVER IDEAS? IN OTHER WORDS, DOES THE AUTHOR SEEM TO RECALL WHAT HE SAID EARLIER AND TO BE IN A POSITION TO INTEGRATE IT INTO POINTS HE HAS MADE SINCE THEN? 
ARE THE POINTS 'REAL'? ARE THEY FRESH? OR IS SOME INSTITUTION OR SOME ACCEPTED VEIN OF PROPAGANDA OR ORTHODOXY JUST USING THE AUTHOR AS A MOUTH PIECE?
IS THE WRITING EVASIVE OR DIRECT? 
ARE THE STATEMENTS AMBIGUOUS? 
DOES THE PROGRESSION OF THE TEXT DEVELOP ACCORDING TO WHO SAID WHAT OR ACCORDING TO WHAT ENTAILS OR CONFIRMS WHAT? 
DOES THE AUTHOR USER OTHER AUTHORS TO DEVELOP HIS IDEAS OR TO CLOAK HIS OWN LACK OF IDEAS?

ADDITIONAL CRITICAL QUESTIONS:
ARE THERE TERMS THAT ARE UNDEFINED BUT SHOULD BE DEFINED, IN THE SENSE THAT, WITHOUT DEFINITIONS, IT IS DIFFICULT OR IMPOSSIBLE TO KNOW WHAT IS BEING SAID OR THEREFORE TO EVALUATE WHAT IS BEING SAID?
ARE THERE "FREE VARIABLES" IN THE TEXT? IE ARE THERE QUALIFICATIONS OR POINTS THAT ARE MADE BUT DO NOT CONNECT TO ANYTHING LATER OR EARLIER?
DO NEW STATEMENTS DEVELOP OUT OF OLD ONES? OR ARE THEY MERELY "ADDED" TO PREVIOUS ONES, WITHOUT IN ANY SENSE BEING GENERATED BY THEM?
DO NEW STATEMENTS CLARIFY OR DO THEY LEAD TO MORE LACK OF CLARITY?
IS THE PASSAGE ACTUALLY (PALPABLY) SMART? OR IS ONLY "PRESUMPTION-SMART"?
IF YOUR JUDGMENT IS THAT IT IS INSIGHTFUL, CAN YOU STATEMENT THAT INSIGHT IN A SINGLE SENTENCE?
HOW WELL DOES IT MAKE ITS CASE?
IF I WERE TO GIVE A HIGH SCORE TO THIS PASSAGE, WOULD I BE REWARDING IMPOSTOR SCAFFOLDING?
IF I WERE TO GIVE A HIGH SCORE TO THIS PASSAGE, WOULD I BE REWARDING CONFORMITY TO ACADEMIC/BUREAUCRATIC NORMS?
IF I WERE TO GIVE A LOW SCORE TO THIS PASSAGE, WOULD I BE PENALIZING ACTUAL INTELLIGENCE OWING TO A LACK OF CONFORMITY TO ACADEMIC/BUREAUCRATIC NORMS?

üö® CRITICAL NEW DIMENSION: GENUINE DEPTH VS. FAUX POSTURING üö®
IS THIS GENUINE INTELLIGENCE OR FAUX-INTELLECTUAL PLACEHOLDER CONTENT?
- HIERARCHICAL LOGIC: Do ideas actually derive logically from each other? Or is the text just SEQUENTIAL/CHRONOLOGICAL listing ("First... Second... Third...") without logical dependencies?
- TERMS WITH DETERMINATE PROPERTIES: Are technical terms grounded with clear meanings? Or are they VAGUE PLACEHOLDERS/BUZZWORDS cited but never defined (e.g., "Myth of the Mental", "disjunctivism", "linguistic idealism" mentioned but not explained)?
- IDEA-DRIVEN VS. AUTHOR-DRIVEN: Does the argument develop based on what entails/confirms what? Or is it AUTHOR-DRIVEN LISTING of "dialogues" and name-dropping without substance?
- MEANINGFUL CRITIQUE VS. ASSERTION: Are claims substantiated? Or does text just ASSERT things are "problematic/dubious/faulty" without explaining why?
- SOCIAL POSTURING: Does text turn intellectual questions into "social exchanges" ("dialogues", "accusations", "X says Y says Z")? This is FAUX-INTELLECTUAL.

‚ö†Ô∏è FAUX-INTELLECTUAL MARKERS (MASSIVE SCORE PENALTIES):
- Sequential listing disguised as argument ‚Üí SCORE ‚â§20/100
- Buzzwords/jargon shuffled without grounding ‚Üí SCORE ‚â§20/100
- Author-driven "dialogue" replacing idea-driven logic ‚Üí SCORE ‚â§20/100
- Vague umbrella claims assuming buzzwords have meaning they lack ‚Üí SCORE ‚â§20/100
- Turning philosophy into social posturing ("X accuses Y of...") ‚Üí SCORE ‚â§20/100

‚úÖ GENUINE INTELLIGENCE MARKERS (HIGH SCORES):
- Hierarchical argumentation where claims build on each other ‚Üí SCORE 90+
- Terms with canonical/determinate meanings used precisely ‚Üí SCORE 90+
- Idea-driven logic (what entails what) ‚Üí SCORE 90+
- Concrete logical relationships and substantive critique ‚Üí SCORE 90+`;

// PHASE 1: Complete protocol with all questions exactly as specified
function createPhase1Prompt(text: string, questions: string): string {
  return `üö® MANDATORY CALIBRATION EXAMPLES üö®
==================================================
STUDY THESE THREE CALIBRATION EXAMPLES CAREFULLY:

EXAMPLE 1 - GENUINE INTELLIGENCE (SCORE: 98/100):
"Sense-perceptions do not have to be deciphered if their contents are to be uploaded, the reason being that they are presentations, not representations. Linguistic expressions do have to be deciphered if their contents are to be uploaded, the reason being that they are representations, not presentations. It is viciously regressive to suppose that information-bearing mental entities are categorically in the nature of representations, as opposed to presentations, and it is therefore incoherent to suppose that thought is mediated by expressions or, therefore, by linguistic entities."
‚Üí SCORE: 98/100 (Hierarchical logic, terms with determinate properties, idea-driven argumentation, precise canonical philosophical terminology)

EXAMPLE 2 - FAUX-INTELLECTUAL PLACEHOLDER (SCORE: 14/100):
"In this dissertation, I critically examine the philosophy of transcendental empiricism. Transcendental empiricism is, among other things, a philosophy of mental content. It attempts to dissolve an epistemological dilemma of mental content by splitting the difference between two diametrically opposed accounts of content. John McDowell's minimal empiricism and Richard Gaskin's minimalist empiricism are two versions of transcendental empiricism. This dissertation is divided into five parts. First, in the Introduction, I state the Wittgensteinian metaphilosophical orientation. Second, I offer a detailed description of McDowell's minimal empiricism. Third, I critique Gaskin's critique. Fourth, I scrutinize the alleged credentials. I then comment on a recent dialogue between transcendental empiricism and Hubert Dreyfus's phenomenology. The dialogue culminates with Dreyfus's accusation of the 'Myth of the Mental.' I argue that this accusation is correct in which case McDowell's direct realism is problematic. I conclude that minimal empiricism does not dissolve the dilemma. Finally, I argue that Tyler Burge successfully undermines the doctrine of disjunctivism."
‚Üí SCORE: 14/100 (Sequential author-driven listing, undefined buzzwords shuffled without grounding, social posturing as inquiry, vague "problematic/dubious" assertions without substance)

EXAMPLE 3 - GENUINE TECHNICAL INTELLIGENCE (SCORE: 97/100):
"We prove there are infinitely many primes using topology on ‚Ñ§. Let the basis for the topology consist of all arithmetic progressions {a + bd | b ‚àà ‚Ñ§} where d > 0. Each basis element is infinite and clopen. Suppose there are only finitely many primes p_1,...,p_r. For each i, the set p_i ‚Ñ§ is clopen. Let U = ‚à™ p_i ‚Ñ§. Then U is clopen. U contains every integer divisible by at least one prime. Thus U = ‚Ñ§ \ {-1, 1}. Since U is clopen, {-1, 1} is clopen, hence open. But {-1, 1} is finite while every non-empty open set is infinite‚Äîcontradiction."
‚Üí SCORE: 97/100 (Hierarchical proof structure, precise mathematical terms, idea-driven logic where each claim builds on previous)

==================================================
üö® CRITICAL: DISTINGUISH GENUINE VS. FAUX INTELLIGENCE üö®
==================================================

The three calibration examples above show the CRITICAL distinction:
- GENUINE philosophical work with hierarchical logic and grounded terms ‚Üí 98/100
- FAUX-INTELLECTUAL placeholder content with buzzwords and sequential listing ‚Üí 14/100
- GENUINE technical/mathematical reasoning with precise terms ‚Üí 97/100

YOU MUST DISTINGUISH BETWEEN:

‚úÖ GENUINE INTELLIGENCE (SCORE 90-98):
- Hierarchical argumentation where claims actually derive from each other
- Technical terms with DETERMINATE PROPERTIES used precisely
- Idea-driven logic (what entails what), not author-driven listing
- Canonical philosophical/mathematical terminology with real grounding
- Example: "Sense-perceptions are presentations, not representations. It is viciously regressive to suppose..." (98/100)

‚ùå FAUX-INTELLECTUAL CONTENT (SCORE ‚â§20):
- Sequential/chronological listing without logical dependencies ("First... Second... Third...")
- Buzzwords cited but NEVER DEFINED or grounded ("Myth of the Mental", "disjunctivism", "linguistic idealism" mentioned but not explained)
- Author-driven "dialogue" replacing idea-driven argument ("McDowell says X, then Gaskin critiques Y, then Dreyfus accuses Z")
- Vague assertions that things are "problematic/dubious/faulty" WITHOUT explaining why
- Social posturing as intellectual inquiry ("dialogues", "accusations")
- Example: "This dissertation examines transcendental empiricism... I critique Gaskin's critique... The dialogue culminates with Dreyfus's accusation..." (14/100)

‚ö†Ô∏è DO NOT CONFUSE:
- Technical jargon with GROUNDING (presentations vs representations with explanation) = GENUINE ‚Üí 98/100
- Technical jargon WITHOUT grounding (disjunctivism mentioned but never explained) = FAUX ‚Üí 14/100
- Assuming prior knowledge in expert discourse (using canonical terms precisely) = GENUINE ‚Üí BOOSTS SCORE
- Buzzword-dropping without substance (citing terms as placeholder labels) = FAUX ‚Üí ‚â§20/100

==================================================

CRITICAL: This is NOT a grading app. You are NOT evaluating academic work. You are assessing INTELLIGENCE ONLY.

FUNDAMENTAL PRINCIPLE: If a text shows brilliance but is insane, it gets a HIGH score. If a text is measured and complies with usual academic norms but is obviously the work of a dumb person, it gets a LOW score.

You are NOT grading. You are NOT applying academic criteria. You are NOT comparing to other academic texts. You are assessing RAW INTELLIGENCE displayed in the writing.

A score of N/100 means the author is smarter than N% of the general population. 83/100 means only 17 out of 100 people are smarter than this author.

Your job: Answer these questions about intelligence and determine what percentage of the population this author surpasses in raw intelligence.

METAPOINT 1: This is NOT a grading app. You assess INTELLIGENCE of what you are given. Brilliant fragment = high score regardless of academic conventions. You are NOT grading essays. You are NOT looking for academic completeness. Answer based purely on intelligence displayed.

METAPOINT 2: Do NOT overvalue academic conventions. Confident speech is not "shutting down inquiry". Casual speech does not mean disorganized thoughts. Judge INTELLIGENCE, not presentation style.

METAPOINT 3: You MUST begin your response with a comprehensive SUMMARY AND GENERAL ANALYSIS section that:
- Summarizes the main arguments, themes, and structure of the text (minimum 2-3 substantial paragraphs)
- Categorizes the text (philosophical, empirical, technical, fiction, etc.)
- Provides an initial overall assessment of the author's approach and writing style
- Identifies key strengths and weaknesses before diving into dimensional analysis
This summary must be thorough and substantive - NOT a brief 2-sentence overview.

METAPOINT 4: DO NOT change scoring based on text category. Advanced scholarship gets evaluated against general population, not just academics.

METAPOINT 5: This is NOT a grading app. Do NOT penalize boldness or unconventional thinking. Raw insight matters, not argumentation style. Smart = smart, period.

METAPOINT 6: Scores are intelligence percentiles: 83/100 means 17/100 people in Walmart are smarter than this author.

METAPOINT 7: EXPLICIT HIGH-END CALIBRATION - What deserves 92-97/100:
- Advanced philosophical argumentation with original analysis: 92-97 by DEFAULT
- Technical scholarship engaging serious literature (Strawson, Quine, Frege, etc.): 92-97 by DEFAULT  
- Novel theoretical claims with rigorous support: 92-97 by DEFAULT
- Sophisticated formal reasoning with clear inferential structure: 92-97 by DEFAULT
- Coherent, technically precise academic work: 92-97 by DEFAULT

METAPOINT 8: ACCESSIBILITY AND PRIOR KNOWLEDGE:
üö® CRITICAL: Assuming prior knowledge BOOSTS intelligence score, NOT lowers it! üö®
- Texts written for expert audiences that assume technical knowledge demonstrate HIGHER intelligence
- Do NOT penalize for "inaccessibility" or "assuming prior knowledge"
- Using canonical technical terms precisely (presentations vs representations, disjunctivism, regress arguments) is a STRENGTH
- Only penalize if undefined terms are PLACEHOLDERS with no determinate meaning (faux-intellectual buzzwords)
- Expert-level discourse assuming shared vocabulary = HIGH SCORE
- Simplified discourse explaining basic concepts = appropriate for audience, but not extra points for accessibility

CRITICAL: Downgrading sophisticated academic/philosophical work below 90/100 requires identifying CATASTROPHIC reasoning failures (major logical contradictions, completely incoherent arguments, fundamental conceptual confusions). Do NOT downgrade for minor quibbles, stylistic preferences, or "it could be more X." If the work shows genuine philosophical sophistication and technical rigor, it MUST score 92+.

${questions}

CRITICAL REQUIREMENTS FOR YOUR ANALYSIS:

1. WRITE EXTREMELY LONG DIMENSIONAL SECTIONS: Each major dimension or question requires MULTIPLE SUBSTANTIAL PARAGRAPHS (minimum 3-5 paragraphs of 6-10 sentences EACH). Your analysis must be comprehensive and thorough, not brief summaries.

2. QUOTE EXTENSIVELY THROUGHOUT: You must include 5-10+ direct quotations for EACH major dimension, woven throughout your multi-paragraph analysis. Every claim must be backed by specific quoted passages.

3. PROVIDE DETAILED ARGUMENTATION: For each dimension, you must:
   - State your assessment with nuance and detail
   - Present 5-10+ direct quotations from the text as evidence
   - Analyze each quotation in depth, explaining what it reveals
   - Build a detailed argument connecting the quotations to your assessment
   - Address counterpoints and complexities
   - Synthesize your findings in a concluding paragraph

4. GROUND EVERY CLAIM IN THE TEXT: Do NOT write things like "The passage is insightful" or "The ideas are fresh." Instead write: "When the author states '[EXACT QUOTE]', this demonstrates [SPECIFIC ANALYSIS]. Furthermore, the passage '[ANOTHER QUOTE]' reveals [DETAILED EXPLANATION]. This pattern continues when we see '[THIRD QUOTE]'..." and so on.

5. SHOW YOU READ THE TEXT DEEPLY: Your response must be so detailed and quotation-heavy that it proves beyond doubt you read and analyzed every part of the specific text. Generic assessments are COMPLETELY UNACCEPTABLE.

6. LENGTH REQUIREMENT: Each major dimensional analysis section should be 500-800 words minimum with extensive quotations and detailed argumentation. Brief responses will be rejected.

Remember: INTELLIGENCE assessment, NOT academic grading. Brilliant but crazy = high score. Dumb but conventional = low score.

EVERY single assessment MUST be backed by direct quotations from the text. Generic platitudes without evidence are completely unacceptable.

Write in plain text only. End with: FINAL SCORE: [actual number]/100

TEXT:
${text}`;
}

// PHASE 2: Pushback exactly as specified
function createPhase2Prompt(score: number, text: string, questions: string): string {
  const peopleOutperforming = 100 - score;
  return `Your position is that ${peopleOutperforming}/100 outperform the author with respect to the cognitive metric defined by the question: that is your position, am I right? And are you sure about that?

Answer the following questions about the text de novo:

${questions}

CRITICAL REQUIREMENTS (SAME AS BEFORE):
1. QUOTE EXTENSIVELY from the text - multiple direct quotations for every assessment
2. WRITE SUBSTANTIAL PARAGRAPHS with detailed evidence-based analysis  
3. GROUND EVERY CLAIM in specific passages from the text
4. NO generic platitudes that could apply to any text
5. Cite at least 2-3 specific quoted passages per major question
6. Minimum 1 full paragraph (4-8 sentences) per major dimension

Your response must prove you read this specific text through extensive quotations and detailed discussion.

End with: FINAL SCORE: [NUMBER]/100

TEXT:
${text}`;
}

// PHASE 3: Walmart metric check exactly as specified
function createPhase3Prompt(score: number): string {
  const peopleOutperforming = 100 - score;
  return `You ask the LLM if its numerical scores (N/100, e.g. 99/100, 42/100) are consistent with the fact that those are to be taken to mean that (100-N) people out of 100 outperform the author in the relevant respect. So if a score of ${score}/100 is awarded to a paper, that means that ${peopleOutperforming}/100 people in Walmart are running rings around this person. Is this consistent with your assessment?

FINAL SCORE: [NUMBER]/100`;
}

// PHASE 4: Accept and report what the LLM says
function createPhase4Prompt(): string {
  return `At this point, you accept and report what the LLM says.

FINAL SCORE: [NUMBER]/100`;
}

// Text chunking function for large texts - 500 words per chunk
function chunkText(text: string, maxWordsPerChunk: number = 500): string[] {
  const words = text.split(' ');
  const chunks: string[] = [];
  
  for (let i = 0; i < words.length; i += maxWordsPerChunk) {
    const chunk = words.slice(i, i + maxWordsPerChunk).join(' ');
    if (chunk.trim()) {
      chunks.push(chunk.trim());
    }
  }
  
  return chunks;
}

// Generic LLM caller
async function callLLMProvider(
  provider: 'openai' | 'anthropic' | 'perplexity' | 'deepseek' | 'grok',
  messages: Array<{role: string, content: string}>
): Promise<string> {
  try {
    if (provider === 'openai') {
      const OpenAI = (await import('openai')).default;
      const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
      
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: messages as any,
        temperature: 0.1
      });
      
      return completion.choices[0]?.message?.content || '';
    } else if (provider === 'anthropic') {
      const Anthropic = (await import('@anthropic-ai/sdk')).default;
      const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
      
      const completion = await anthropic.messages.create({
        model: "claude-3-7-sonnet-20250219",
        max_tokens: 4000,
        messages: messages as any,
        temperature: 0.1
      });
      
      return completion.content[0]?.type === 'text' ? completion.content[0].text : '';
    } else if (provider === 'perplexity') {
      const response = await fetch('https://api.perplexity.ai/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: "sonar",
          messages: messages,
          temperature: 0.1
        })
      });
      
      const data = await response.json();
      return data.choices?.[0]?.message?.content || '';
    } else if (provider === 'deepseek') {
      const response = await fetch('https://api.deepseek.com/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: "deepseek-chat",
          messages: messages,
          temperature: 0.1
        })
      });
      
      const data = await response.json();
      return data.choices?.[0]?.message?.content || '';
    } else if (provider === 'grok') {
      const response = await fetch('https://api.x.ai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.GROK_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: "grok-3",
          messages: messages,
          temperature: 0.1
        })
      });
      
      const data = await response.json();
      return data.choices?.[0]?.message?.content || '';
    }
    
    return '';
  } catch (error) {
    console.error(`Error calling ${provider}:`, error);
    return '';
  }
}

// Score extraction function
function extractScore(text: string): number {
  console.log(`EXTRACTING SCORE FROM RESPONSE LENGTH: ${text.length}`);
  
  // Look for final score pattern first
  const finalScoreMatch = text.match(/FINAL SCORE:\s*(\d+)\/100/i);
  if (finalScoreMatch) {
    const score = parseInt(finalScoreMatch[1]);
    console.log(`EXTRACTED FINAL SCORE FORMAT: ${score}/100`);
    return score;
  }
  
  // Look for explicit numerical score
  const explicitMatch = text.match(/(\d+)\/100/g);
  if (explicitMatch && explicitMatch.length > 0) {
    const lastMatch = explicitMatch[explicitMatch.length - 1];
    const score = parseInt(lastMatch.split('/')[0]);
    console.log(`EXTRACTED NUMERICAL SCORE: ${score}/100`);
    return score;
  }
  
  console.log('NO SCORE FOUND, defaulting to 0');
  return 0;
}

// NORMAL PROTOCOL - Phase 1 only
export async function executeNormalProtocol(
  text: string,
  provider: 'openai' | 'anthropic' | 'perplexity' | 'deepseek' | 'grok'
): Promise<any> {
  console.log(`NORMAL INTELLIGENCE ANALYSIS WITH ${provider.toUpperCase()} - PHASE 1 ONLY`);
  console.log(`EXECUTING PHASE 1 ONLY FOR INTELLIGENCE WITH ${provider.toUpperCase()}`);
  
  const questions = EXACT_COMPLETE_QUESTIONS;
  
  // PHASE 1: Initial evaluation
  const phase1Prompt = createPhase1Prompt(text, questions);
  const phase1Response = await callLLMProvider(provider, [
    { role: 'user', content: phase1Prompt }
  ]);
  let finalScore = extractScore(phase1Response);
  
  console.log(`PHASE 1 COMPLETE: Score ${finalScore}/100`);
  
  const cleanedResponse = phase1Response.replace(/\*{1,3}/g, '').replace(/#{1,6}\s*/g, '').trim();
  console.log(`PHASE 1 RESPONSE PREVIEW: "${cleanedResponse.substring(0, 200)}..."`);
  console.log(`PHASE 1 FULL RESPONSE LENGTH: ${cleanedResponse.length} characters`);
  
  return {
    provider,
    overallScore: finalScore,
    analysis: cleanedResponse,
    evaluationType: 'intelligence',
    formattedReport: cleanedResponse,
    rawResponse: phase1Response // DEBUG: Include raw response
  };
}

// COMPREHENSIVE PROTOCOL - All 4 phases with chunking for high quality
export async function executeComprehensiveProtocol(
  text: string,
  provider: 'openai' | 'anthropic' | 'deepseek' | 'perplexity' | 'grok'
): Promise<any> {
  console.log(`CHUNKED 4-PHASE INTELLIGENCE EVALUATION: Analyzing ${text.length} characters with protocol`);
  console.log(`EXECUTING CHUNKED 4-PHASE PROTOCOL FOR INTELLIGENCE WITH ${provider.toUpperCase()}`);
  
  const questions = EXACT_COMPLETE_QUESTIONS;
  
  // CHUNK THE TEXT FOR HIGH QUALITY ANALYSIS - 500 words per chunk
  const chunks = chunkText(text, 500); // 500 words per chunk as requested
  console.log(`TEXT SPLIT INTO ${chunks.length} CHUNKS (500 words each) for comprehensive analysis`);
  
  let combinedAnalyses: string[] = [];
  let chunkScores: number[] = [];
  
  // ANALYZE EACH CHUNK SEPARATELY
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];
    console.log(`PHASE 1 CHUNK ${i+1}/${chunks.length}: Analyzing ${chunk.length} characters`);
    
    const chunkPrompt = createPhase1Prompt(chunk, questions);
    const chunkResponse = await callLLMProvider(provider, [
      { role: 'user', content: chunkPrompt }
    ]);
    
    combinedAnalyses.push(chunkResponse);
    chunkScores.push(extractScore(chunkResponse));
    
    console.log(`CHUNK ${i+1} SCORE: ${chunkScores[i]}/100`);
  }
  
  // COMBINE ALL CHUNK ANALYSES
  const combinedText = combinedAnalyses.join('\n\n---CHUNK SEPARATOR---\n\n');
  const averageScore = Math.round(chunkScores.reduce((a, b) => a + b, 0) / chunkScores.length);
  let phase1Score = averageScore;
  
  let phase2Response = '';
  let phase2Score = phase1Score;
  
  console.log(`PHASE 1 AVERAGE SCORE: ${phase1Score}/100 across ${chunks.length} chunks`);
  
  // PHASE 2: Pushback if score < 95 (using first chunk for efficiency)
  if (phase1Score < 95) {
    console.log(`PHASE 2: Score ${phase1Score} < 95, applying pushback to first chunk`);
    const phase2Prompt = createPhase2Prompt(phase1Score, chunks[0], questions);
    phase2Response = await callLLMProvider(provider, [
      { role: 'user', content: phase2Prompt }
    ]);
    phase2Score = extractScore(phase2Response);
  } else {
    console.log(`PHASE 2: Score ${phase1Score} >= 95, no pushback needed`);
    phase2Response = 'No pushback needed - score was already >= 95/100';
  }
  
  // PHASE 3: Walmart metric check
  console.log("PHASE 3: Walmart metric consistency check");
  const phase3Prompt = createPhase3Prompt(phase2Score);
  const phase3Response = await callLLMProvider(provider, [
    { role: 'user', content: phase3Prompt }
  ]);
  let phase3Score = extractScore(phase3Response);
  
  // PHASE 4: Final validation and acceptance
  console.log("PHASE 4: Final validation");
  const phase4Prompt = createPhase4Prompt();
  const phase4Response = await callLLMProvider(provider, [
    { role: 'user', content: phase4Prompt }
  ]);
  let finalScore = extractScore(phase4Response);
  
  // Use Phase 4 score, or best previous score if Phase 4 fails
  if (finalScore <= 0 || finalScore > 100) {
    // Only use fallback if Phase 4 completely failed to extract a score
    finalScore = Math.max(phase1Score, phase2Score, phase3Score);
    console.log(`PHASE 4 RESULT: Score extraction failed, using best previous score ${finalScore}/100`);
  } else {
    console.log(`PHASE 4 RESULT: Final score ${finalScore}/100`);
  }
  
  // Clean up response formatting
  const cleanResponse = (text: string) => {
    return text
      .replace(/\*{1,3}/g, '') // Remove asterisks
      .replace(/#{1,6}\s*/g, '') // Remove hashtags
      .replace(/\-{3,}/g, '') // Remove horizontal lines
      .replace(/\_{3,}/g, '') // Remove underscores
      .replace(/\n{3,}/g, '\n\n') // Reduce multiple newlines
      .trim();
  };

  // Detailed phase breakdown for comprehensive reports
  const phases = {
    phase1: {
      score: phase1Score,
      response: cleanResponse(combinedText),
      prompt: "Chunked Intelligence Evaluation using exact 18-question protocol"
    },
    phase2: {
      score: phase2Score,
      response: cleanResponse(phase2Response),
      applied: phase1Score < 95
    },
    phase3: {
      score: phase3Score,
      response: cleanResponse(phase3Response)
    },
    phase4: {
      score: finalScore,
      response: cleanResponse(phase4Response)
    }
  };

  return {
    provider,
    overallScore: finalScore,
    analysis: cleanResponse(combinedText), // Combined analysis from all chunks
    phases, // Detailed breakdown of all phases
    evaluationType: 'intelligence',
    formattedReport: cleanResponse(combinedText) // Combined comprehensive analysis
  };
}

// Unified function for backward compatibility 
export async function executeFourPhaseProtocol(
  text: string,
  provider: 'openai' | 'anthropic' | 'perplexity' | 'deepseek' | 'grok',
  evaluationType: string = 'intelligence',
  mode: 'normal' | 'comprehensive' = 'comprehensive'
): Promise<any> {
  if (mode === 'normal') {
    return executeNormalProtocol(text, provider);
  } else {
    return executeComprehensiveProtocol(text, provider);
  }
}