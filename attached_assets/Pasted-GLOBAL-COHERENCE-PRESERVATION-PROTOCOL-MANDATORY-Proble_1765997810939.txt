GLOBAL COHERENCE PRESERVATION PROTOCOL (MANDATORY)

Problem: Texts exceed token limits and must be chunked (~1000 words). Coherence must be preserved across chunks, not merely within them.

Core Rule:
Coherence is a relational property across chunks. Therefore, each chunk must be processed with awareness of global continuity signals, not merely checked for internal quality.

STEP 1 — GLOBAL CONTEXT EXTRACTION (LIGHTWEIGHT, NON-GENERATIVE)

Before any chunk-level coherence analysis, generate and store a Global Context Object (GCO) containing ONLY the following (no rewriting, no evaluation):

Core topic(s)

Central explanatory framework (if any)

Key concepts / variables / entities

Argument direction (if present)

Emotional / motivational trajectory (if present)

Instructional goal (if present)

Mathematical assumptions or proof target (if present)

This object must be ≤ 300 words and stored once per document.

STEP 2 — CHUNK-LEVEL COHERENCE EVALUATION WITH GLOBAL CONTEXT INJECTION

For each chunk, inject:

The chunk text

The Global Context Object

The selected Coherence Mode

The model must evaluate the chunk relative to the GCO, not in isolation.

STEP 3 — MODE-SPECIFIC CROSS-CHUNK COHERENCE RULES

Apply exactly ONE of the following lenses per run:

Logical Consistency

Check for contradictions between this chunk and the GCO

Ignore argument strength or style

Logical Cohesiveness

Check whether this chunk advances, supports, or presupposes argumentative steps implied by the GCO

Flag gaps, jumps, or regressions relative to earlier structure

Scientific / Explanatory

Check whether explanations in this chunk:

Use the same causal level as the GCO

Do not switch from mechanism → correlation or vice versa

Preserve explanatory direction across chunks

Thematic / Psychological

Check whether tone, affect, and psychological framing continue or intentionally shift relative to the GCO

Flag abrupt or unjustified affective breaks

Instructional

Check whether this chunk:

Presupposes steps not yet introduced

Reorders instructions inconsistently

Breaks actionability established earlier

Motivational

Check whether emotional direction (urgency, encouragement, warning, etc.) remains aligned with the GCO

Flag motivational reversals or dilution

Mathematical (Proof Validity)

Check whether this chunk:

Uses assumptions consistent with the GCO

Does not invoke results not yet established

Preserves proof direction (forward, backward, contradiction, induction)

Philosophical (Conceptual Rigor)

Check whether core concepts retain the same meaning, scope, and contrast classes as defined or implied in the GCO

Flag equivocation, category drift, or silent redefinition

Auto-Detect

Infer which single coherence mode best fits the text

Apply ONLY that mode

STEP 4 — OUTPUT FORMAT (NO NULL RESULTS)

For each chunk, return:

Coherence status relative to GCO (preserved / weakened / shifted)

Specific location(s) of coherence strain (if any)

Nearest adjacent repair suggestion (minimal, local, optional)

Never return “incoherent,” “error,” or “cannot evaluate.”

STEP 5 — OPTIONAL FINAL PASS (AGGREGATED)

After all chunks:

Evaluate the GCO itself for drift based on chunk feedback

Update GCO only if changes are forced by the text (no optimization)

ENFORCEMENT RULE

No chunk may be evaluated, rewritten, or scored without the Global Context Object present.