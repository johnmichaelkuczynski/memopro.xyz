TASK: Implement Cross-Chunk Coherence (CC) for the Reconstruction Function
The Reconstruction function currently processes long documents by dividing them into chunks and reconstructing each chunk independently. This creates "Frankenstein" outputs where chunks contradict each other, terminology drifts, and commitments made in one chunk are violated in another.
Implement a three-pass architecture to solve this:
PARAMETERS:

Maximum input length: 5000 words
Chunk size: approximately 800 words
Chunk boundaries must fall at paragraph or section breaks, not mid-sentence. Implement smart chunking that respects document structure.

ARCHITECTURE:
Pass 1 — Global Skeleton Extraction (before any reconstruction)
Before chunking, run one pass over the full input document that extracts and stores:

Outline: 8-20 numbered claims or sections identifying the document's structure
Thesis: The central argument or purpose of the document
Key Terms: Important terms with their intended meanings as used in this document
Commitment Ledger: Explicit commitments — "The document asserts X, rejects Y, assumes Z"
Entities: People, organizations, policies, variables, technical terms that must be referenced consistently
Audience Parameters: Who this reconstruction is targeting (carried from user input)
Rigor Level: The reconstruction standard being applied (carried from user input)

Store this skeleton as document_skeleton in the database (JSON format).
This pass must be SHORT — it extracts structure, it does not rewrite anything.
Pass 2 — Constrained Chunk Reconstruction
Divide the input into chunks of approximately 800 words (respecting paragraph boundaries).
For each chunk, send to the model:

The chunk text
The full global skeleton (or relevant portions if skeleton is large)
Strict instruction: "You must not contradict the commitment ledger. You must use key terms as defined in the skeleton. You must maintain consistency with the thesis and outline. If you detect a conflict between the chunk content and the skeleton, flag it explicitly rather than silently introducing inconsistency."

Each chunk reconstruction returns:

The reconstructed chunk text
A delta report: new claims introduced, terms used, any conflicts detected, any additions to the commitment ledger

Store each chunk result as chunk_output with its chunk_delta in the database.
Pass 3 — Global Consistency Stitch
After all chunks are processed, run one final pass that receives:

The global skeleton
All chunk delta reports (not the full reconstructed chunks)
The sequence of reconstructed chunks

This pass:

Detects cross-chunk contradictions, terminology drift, missing premises, redundancies
Generates a conflict list with specific locations
Produces a repair plan identifying which chunks need adjustment and how
Executes micro-repairs only on flagged chunks
Assembles the final coherent output

Store the validation result as document_validation and the final output as final_reconstruction.
DATABASE SCHEMA (Neon):
Create or modify tables as needed:
sql-- Store document-level state
CREATE TABLE IF NOT EXISTS reconstruction_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id TEXT,
    title TEXT,
    original_text TEXT,
    global_skeleton JSONB,
    final_output TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Store per-chunk state
CREATE TABLE IF NOT EXISTS reconstruction_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES reconstruction_documents(id),
    chunk_index INTEGER,
    chunk_input_text TEXT,
    chunk_output_text TEXT,
    chunk_delta JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Store processing runs for audit/debugging
CREATE TABLE IF NOT EXISTS reconstruction_runs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES reconstruction_documents(id),
    run_type TEXT, -- 'skeleton', 'chunk_pass', 'stitch'
    run_input JSONB,
    run_output JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
CRITICAL RULES:

If a chunk conflicts with the global skeleton, the model must either:

Produce the closest adjacent repair that preserves intent, OR
Return a specific flagged conflict with a proposed minimal change
NEVER silently contradict the skeleton
NEVER respond with "can't" — always produce output or a repair proposal


The skeleton extraction pass must be fast and lightweight — do not attempt to reconstruct or rewrite during skeleton extraction.
Chunk boundaries must respect document structure. Prefer breaking at paragraph ends. Never break mid-sentence.
All three passes must complete before returning final output to the user.
Store all intermediate state in the database so that failures can be debugged and resumed.

INTEGRATION:
This architecture replaces the current chunk-and-reassemble logic in the Reconstruction function. The existing reconstruction prompts and parameters (aggressiveness, rigor level, audience, etc.) should be preserved and passed into Pass 2 as part of the chunk reconstruction context.